
#第八章 大数据？了不起！

在2012年，许多科技媒体的头条关注了大数据。是什么让数据变大，为什么“大”重要？在这一章，我们讨论这些问题后面的争议。掌握了前一章的知识后，对于数据的规模如何影响我们的数据工作，我们可以有更多的思考。

市场观察（一个华尔街期刊）最近发表了一篇文章标题为“谷歌IT和商务专业人士指出大数据等于大回报”，副标题“根据新的全球调查，70%的组织正在考虑、计划或者运行大数据项目”。相似的技术新闻在这几年屡见不鲜。如此大量这样的文章让人不由得认为“大数据”是一种给这个世界掀起信息和技术浪潮的革命。但这是真的的？“大数据”真的改变了一切吗？

商业分析师Doug Laney指出三个特征让大数据跟以往的技术革命不同：规模，效率，多样性。规模指的是庞大的数据量。效率则是数据的快速生成和更新。最后，多样性反映会有多种不同类型的数据。这三个特性经常指代大数据的“3V”模型。但是，即使在计算机时代的破晓，我们就已经拥有多样的数据，有的数据产生非常快，而且经过时间的推移，这些数据能装满大量的存储器（试想，从18世纪开始，美国国会图书馆每年产生的多种的大量的数据）。所以，光凭某人说他们面临大规模的、高效率的、多样性的数据问题，很难说大数据是一个崭新的事物。

有这样的说法，和几年前相比，许多进行中的改变让今天的数据问题有了质的不同。让我们列下几个准确的例子：
1. 传感器（比如条形码阅读器）价格的下降和最近几年是它价格下降并且更容易收集更多数据的技术。
2. 相似的，存储器价格的下降使不管质量和使用地保存大量无关紧要的数据变得现实了。
3. 许多人对隐私的态度不再像以前那样严格，他们似乎已经适应了使用Facebook和其他会透露许多个人信息的平台。
4. 研究者已经在机器学习算法中取得了重大进步，它是构建许多数据挖掘的基础。
5. 当一个数据集达到一定规模（几千行），传统的统计显著性检验已经没有意义了，因为即使最小最微不足道的结果（或者效应量，按照统计学家的说法）也是统计上显著的

出了以上这几点，我们能然有许多需要做出的改变：
A.垃圾进，垃圾出：数据的用处非常依赖它是如何收集的。数据收集后，它的质量非常依赖我们如何对它做预处理：数据清理和数据筛选。
B.大等于怪异：如果你寻找异常现象-违反规则的罕见事件-那么数据量越大越好。低频率事件经常不会出现直到数据收集持续很长一段时间，或者包含一个足够大的样例组来专门记录一个奇特案例。
C.连接增加可能：单个数据集不管提供什么变量都有内在的限制。但是如果这些数据能连接到别的数据，新的分析途径也许会突然出现。虽然不能保证，但是你连接越多的数据，你就越有可能有新的发现。





